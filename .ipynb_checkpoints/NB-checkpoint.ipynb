{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis dari Instagram comments calon Presiden 2024 sebelum dan sesudah deklrasi calon wakil presiden menggunakan Naive Bayes\n",
    "\n",
    "\n",
    "## Tujuan : mengetahui perbedaan sentiment dari komentar instagram sebelum dan sesudah deklarasi calon wakil presiden\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "    Aurelius Ivan Wijaya (00000054769)\n",
    "    </li>\n",
    "    <li>\n",
    "    Rajendra Abhinaya (00000060445)\n",
    "    </li>\n",
    "    <li>\n",
    "    Maecyntha Irelynn Tantra (00000055038)\n",
    "    </li>\n",
    "    <li>\n",
    "    Patricia Theodora (00000054093)\n",
    "    </li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "apa sih yang sebenernya kita cari?\n",
    "* web scrapping algoritm untuk data primer (ivan)\n",
    "* labeling (pat)\n",
    "* data sekunder (mae)\n",
    "* stopword library indonesia (abhi)\n",
    "* cari jurnal referensi yang sudah, sebagai literature review (all, min 4 per person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import dataset\n",
    "# [ Primary Dataset ]\n",
    "anies_before = pd.read_csv('./Dataset/Anies/anies_before.csv')\n",
    "anies_after = pd.read_csv('./Dataset/Anies/anies_after.csv')\n",
    "ganjar_before = pd.read_csv('./Dataset/Ganjar/ganjar_before.csv')\n",
    "ganjar_after = pd.read_csv('./Dataset/Ganjar/ganjar_after.csv')\n",
    "prabowo_before = pd.read_csv('./Dataset/Prabowo/prabowo_before.csv')\n",
    "prabowo_after = pd.read_csv('./Dataset/Prabowo/prabowo_after.csv')\n",
    "\n",
    "# [ Secondary Dataset ]\n",
    "instagram_cyber_comments = pd.read_csv('./Dataset/dataset_komentar_instagram_cyberbullying.csv')\n",
    "tweet_tv = pd.read_csv('./Dataset/dataset_tweet_sentimen_tayangan_tv.csv')\n",
    "tweet_pilkada = pd.read_csv('./Dataset/dataset_tweet_sentiment_pilkada_DKI_2017.csv')\n",
    "tweet_opini_film = pd.read_csv('./Dataset/dataset_tweet_sentiment_opini_film.csv')\n",
    "tweet_cellular = pd.read_csv('./Dataset/dataset_tweet_sentiment_cellular_service_provider.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;USERNAME&gt; TOLOL!! Gak ada hubungan nya kegug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geblek lo tata...cowo bgt dibela2in balikan......</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kmrn termewek2 skr lengket lg duhhh kok labil ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intinya kalau kesel dengan ATT nya, gausah ke ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  label\n",
       "0   <USERNAME> TOLOL!! Gak ada hubungan nya kegug...      0\n",
       "1  Geblek lo tata...cowo bgt dibela2in balikan......      0\n",
       "2  Kmrn termewek2 skr lengket lg duhhh kok labil ...      0\n",
       "3  Intinya kalau kesel dengan ATT nya, gausah ke ...      0\n",
       "4  hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1: positive, 0: negative \n",
    "\n",
    "# data integration\n",
    "# instagram_cyber_comments\n",
    "# instagram_cyber_comments['label'] = 1\n",
    "# change label name to 'comments'\n",
    "instagram_cyber_comments.rename(columns={'Instagram Comment Text': 'comments'}, inplace=True)\n",
    "# mapping sentiment\n",
    "instagram_cyber_comments['Sentiment'] = instagram_cyber_comments['Sentiment'].map({'positive': 1, 'negative': 0})\n",
    "instagram_cyber_comments['label'] = instagram_cyber_comments['Sentiment'].astype(int)\n",
    "# drop unused columns\n",
    "instagram_cyber_comments.drop(columns=['Id', 'Sentiment'], inplace=True)\n",
    "# display(instagram_cyber_comments.head())\n",
    "#change data type to string to ensure all data type is string\n",
    "instagram_cyber_comments['comments'] = instagram_cyber_comments['comments'].astype(str)\n",
    "\n",
    "# tweet_tv\n",
    "# change label name to 'comments'\n",
    "tweet_tv.rename(columns={'Tweet': 'comments'}, inplace=True)\n",
    "# mapping sentiment\n",
    "tweet_tv['Sentiment'] = tweet_tv['Sentiment'].map({'positive': 1, 'negative': 0})\n",
    "tweet_tv['label'] = tweet_tv['Sentiment'].astype(int)\n",
    "tweet_tv.rename(columns={'Text Tweet': 'comments'}, inplace=True)\n",
    "tweet_tv.drop(columns=['Id', 'Sentiment', \"Jumlah Retweet\", \"Acara TV\"], inplace=True)\n",
    "#change data type to string to ensure all data type is string\n",
    "tweet_tv['comments'] = tweet_tv['comments'].astype(str)\n",
    "\n",
    "# tweet_pilkada\n",
    "# tweet_pilkada add new column 'label'\n",
    "# tweet_pilkada['label'] = tweet_pilkada['Sentiment'].map({'positive': 1, 'negative': 0}).astype(int)\n",
    "tweet_pilkada['Sentiment'] = tweet_pilkada['Sentiment'].map({'positive': 1, 'negative': 0}).astype(int)\n",
    "# tweet_pilkada['label'] = tweet_pilkada['Sentiment'].astype(int)\n",
    "tweet_pilkada = tweet_pilkada[['Sentiment', 'Text Tweet']]\n",
    "tweet_pilkada.rename(columns={'Text Tweet': 'comments'}, inplace=True)\n",
    "tweet_pilkada.rename(columns={'Sentiment': 'label'}, inplace=True)\n",
    "#change data type to string to ensure all data type is string\n",
    "tweet_pilkada['comments'] = tweet_pilkada['comments'].astype(str)\n",
    "\n",
    "# tweet_opini_film\n",
    "# change label name to 'comments'\n",
    "tweet_opini_film.rename(columns={'Tweet': 'comments'}, inplace=True)\n",
    "# mapping sentiment\n",
    "tweet_opini_film['Sentiment'] = tweet_opini_film['Sentiment'].map({'positive': 1, 'negative': 0})\n",
    "tweet_opini_film['label'] = tweet_opini_film['Sentiment'].astype(int)\n",
    "tweet_opini_film.drop(columns=['Id', 'Sentiment'], inplace=True)\n",
    "tweet_opini_film.rename(columns={'Text Tweet': 'comments'}, inplace=True)\n",
    "#change data type to string to ensure all data type is string\n",
    "tweet_opini_film['comments'] = tweet_opini_film['comments'].astype(str)\n",
    "\n",
    "# tweet_cellular\n",
    "# change label name to 'comments'\n",
    "tweet_cellular.rename(columns={'Tweet': 'comments'}, inplace=True)\n",
    "# mapping sentiment\n",
    "tweet_cellular['Sentiment'] = tweet_cellular['Sentiment'].map({'positive': 1, 'negative': 0})\n",
    "tweet_cellular['label'] = tweet_cellular['Sentiment'].astype(int)\n",
    "tweet_cellular.drop(columns=['Id', 'Sentiment'], inplace=True)\n",
    "tweet_cellular.rename(columns={'Text Tweet': 'comments'}, inplace=True)\n",
    "# integrate all secondary dataset\n",
    "secondary_dataset = pd.concat([instagram_cyber_comments, tweet_tv, tweet_pilkada, tweet_opini_film, tweet_cellular], ignore_index=True)\n",
    "#change data type to string to ensure all data type is string\n",
    "secondary_dataset['comments'] = secondary_dataset['comments'].astype(str)\n",
    "\n",
    "display(secondary_dataset.head())\n",
    "# convert to csv\n",
    "# secondary_dataset.to_csv('./Dataset/secondary_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;USERNAME&gt; TOLOL!! Gak ada hubungan nya kegug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geblek lo tata...cowo bgt dibela2in balikan......</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kmrn termewek2 skr lengket lg duhhh kok labil ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intinya kalau kesel dengan ATT nya, gausah ke ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  label\n",
       "0   <USERNAME> TOLOL!! Gak ada hubungan nya kegug...      0\n",
       "1  Geblek lo tata...cowo bgt dibela2in balikan......      0\n",
       "2  Kmrn termewek2 skr lengket lg duhhh kok labil ...      0\n",
       "3  Intinya kalau kesel dengan ATT nya, gausah ke ...      0\n",
       "4  hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(secondary_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Proccessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleMissingValue(df):\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    # df = df.reset_index(drop=True)  \n",
    "    # set column name\n",
    "    # pick only comments features\n",
    "    df = df[['comments']] \n",
    "    # df.columns = ['column']\n",
    "    return df\n",
    "# prabowo_after = prabowo_after.dropna()\n",
    "\n",
    "anies_before['comments'] = handleMissingValue(anies_before)\n",
    "anies_after['comments'] = handleMissingValue(anies_after)\n",
    "ganjar_before['comments'] = handleMissingValue(ganjar_before)\n",
    "ganjar_after['comments'] = handleMissingValue(ganjar_after)\n",
    "prabowo_before['comments'] = handleMissingValue(prabowo_before)\n",
    "prabowo_after['comments'] = handleMissingValue(prabowo_after)\n",
    "secondary_dataset['comments'] = handleMissingValue(secondary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;USERNAME&gt; TOLOL!! Gak ada hubungan nya kegug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geblek lo tata...cowo bgt dibela2in balikan......</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kmrn termewek2 skr lengket lg duhhh kok labil ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intinya kalau kesel dengan ATT nya, gausah ke ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  label\n",
       "0   <USERNAME> TOLOL!! Gak ada hubungan nya kegug...      0\n",
       "1  Geblek lo tata...cowo bgt dibela2in balikan......      0\n",
       "2  Kmrn termewek2 skr lengket lg duhhh kok labil ...      0\n",
       "3  Intinya kalau kesel dengan ATT nya, gausah ke ...      0\n",
       "4  hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200 entries, 0 to 2199\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   comments  2191 non-null   object\n",
      " 1   label     2200 non-null   int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 25.9+ KB\n"
     ]
    }
   ],
   "source": [
    "display(secondary_dataset.head())\n",
    "\n",
    "secondary_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Folding\n",
    "\n",
    "handle case folding to make sure all the words are in the same case (lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tombol tolak muhaimin, gak ush takut kehilanga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@alfarouqxoumar amit2 milih muhaimin, sama aja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@akbar_brox capres abadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>@alfarouqxoumar memangnya ada apa dengan suara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>@alfarouqxoumar kasian ahy, ditinggal begitu aja.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           comments\n",
       "0      0  tombol tolak muhaimin, gak ush takut kehilanga...\n",
       "1      0  @alfarouqxoumar amit2 milih muhaimin, sama aja...\n",
       "2      1                           @akbar_brox capres abadi\n",
       "3      2  @alfarouqxoumar memangnya ada apa dengan suara...\n",
       "4      3  @alfarouqxoumar kasian ahy, ditinggal begitu aja."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "# Handle case folding\n",
    "# def case_folding(data):\n",
    "#     datatemps = []\n",
    "#     for i in range(0, len(data)):\n",
    "#         try:\n",
    "#             print(data['comments'][i])\n",
    "#             commentTemp = data['comments'][i]\n",
    "#             datatemps.append(commentTemp.str.lower())\n",
    "#             #lower case\n",
    "#             commentTemp = data\n",
    "#         except KeyError as e:\n",
    "#             # print(f\"KeyError at index {i}: {e}\")\n",
    "#             pass # skip the row if there is no comment\n",
    "#     datatemps = {'comments': datatemps}\n",
    "#     return pd.DataFrame(datatemps)\n",
    "\n",
    "def case_folding(data):\n",
    "    datatemps = []\n",
    "    for i in range(0, len(data)):\n",
    "        try:\n",
    "            commentTemp = data['comments'][i]\n",
    "            if isinstance(commentTemp, str):  # Check if the value is a string\n",
    "                datatemps.append(commentTemp.lower())\n",
    "        except KeyError as e:\n",
    "            # print(f\"KeyError at index {i}: {e}\")\n",
    "            pass  # skip the row if there is no comment\n",
    "    datatemps = {'comments': datatemps}\n",
    "    return pd.DataFrame(datatemps)\n",
    "    \n",
    "\n",
    "anies_before['comments'] =  pd.DataFrame(case_folding(anies_before))\n",
    "anies_after['comments'] =  pd.DataFrame(case_folding(anies_after))\n",
    "ganjar_before['comments'] =  pd.DataFrame(case_folding(ganjar_before))\n",
    "ganjar_after['comments'] =  pd.DataFrame(case_folding(ganjar_after))\n",
    "prabowo_before['comments'] =  pd.DataFrame(case_folding(prabowo_before))\n",
    "prabowo_after['comments'] =  pd.DataFrame(case_folding(prabowo_after))\n",
    "secondary_dataset['comments'] =  pd.DataFrame(case_folding(secondary_dataset))\n",
    "\n",
    "display(anies_after.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation & Number & Whitespace Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def remove_punct(data):\n",
    "    datatemps = []\n",
    "    for i in range(0, len(data)):\n",
    "        comment = str(data.iloc[i, 0])  # Convert to string\n",
    "        comment = re.sub(\"@[^\\s]+\", \"\", comment)  # remove @user\n",
    "        comment = re.sub(r'[^\\w\\s]', '', comment)  # Remove punctuation\n",
    "        comment = comment.strip()  # Remove whitespace\n",
    "        comment = re.sub(r'\\s+', ' ', comment)  # Remove double spacing\n",
    "        comment = comment.strip()  # Remove whitespace\n",
    "        comment = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', comment)  # Remove single characters\n",
    "        comment = re.sub(r'\\d+', '', comment)  # Remove numbers\n",
    "        # remove tags\n",
    "        comment = re.sub(\"&lt;/?.*?&gt;\", \" &lt;&gt; \", comment)\n",
    "        # remove special characters and digits\n",
    "        comment = re.sub(\"(\\\\d|\\\\W)+\", \" \", comment)\n",
    "        \n",
    "        datatemps.append(comment)\n",
    "    return datatemps\n",
    "\n",
    "# Call the functions successively\n",
    "anies_before['comments'] = pd.DataFrame(remove_punct(anies_before))\n",
    "anies_after['comments'] = pd.DataFrame(remove_punct(anies_after))\n",
    "ganjar_before['comments'] = pd.DataFrame(remove_punct(ganjar_before))\n",
    "ganjar_after['comments'] = pd.DataFrame(remove_punct(ganjar_after))\n",
    "prabowo_before['comments'] = pd.DataFrame(remove_punct(prabowo_before))\n",
    "prabowo_after['comments'] = pd.DataFrame(remove_punct(prabowo_after))\n",
    "secondary_dataset['comments'] = pd.DataFrame(remove_punct(secondary_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index comments\n",
       "0      0         \n",
       "1      0         \n",
       "2      1         \n",
       "3      2         \n",
       "4      3         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(anies_after.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Normalization / Noise Removal\n",
    "\n",
    "* this one need research (ivan)\n",
    "* slang word dataset that i used : https://github.com/nasalsabila/kamus-alay\n",
    "\n",
    "* Contoh sebelum: \"Para mahasiswa yang memperoleh nilai yang rendah dalam ujian tidak diizinkan untuk mengikuti ujian ulang.\"\n",
    "* Contoh sesudah: \"Mahasiswa yang memperoleh nilai rendah dalam ujian tidak diizinkan mengikuti ujian ulang.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "indo_slang_word = pd.read_csv('./Dataset/TextNormalization/colloquial-indonesian-lexicon.csv')\n",
    "indo_slang_word.head()\n",
    "\n",
    "def replace_slang_word(doc,slang_word):\n",
    "    for index in  range(0,len(doc)-1):\n",
    "        index_slang = slang_word.slang==doc[index]\n",
    "        formal = list(set(slang_word[index_slang].formal))\n",
    "        if len(formal)==1:\n",
    "            doc[index]=formal[0]\n",
    "    return doc\n",
    "\n",
    "# def text_normalization(data):\n",
    "#     datatemps = []\n",
    "#     for i in range(0, len(data)):\n",
    "#         comment = data.iloc[i, 0]  # Access the 'comments' column in the DataFrame\n",
    "#         comment = comment.split()\n",
    "#         comment = replace_slang_word(comment,indo_slang_word)\n",
    "#         comment = ' '.join(comment)\n",
    "#         datatemps.append(comment)\n",
    "#     return datatemps\n",
    "\n",
    "def text_normalization(data):\n",
    "    datatemps = []\n",
    "    for i in range(0, len(data)):\n",
    "        comment = str(data.iloc[i, 0])  # Convert to string\n",
    "        comment = comment.split()\n",
    "        comment = replace_slang_word(comment, indo_slang_word)\n",
    "        comment = ' '.join(comment)\n",
    "        datatemps.append(comment)\n",
    "    return datatemps\n",
    "\n",
    "# Call the functions successively\n",
    "anies_before['comments'] = pd.DataFrame(text_normalization(anies_before))\n",
    "anies_after['comments'] = pd.DataFrame(text_normalization(anies_after))\n",
    "ganjar_before['comments'] = pd.DataFrame(text_normalization(ganjar_before))\n",
    "ganjar_after['comments'] = pd.DataFrame(text_normalization(ganjar_after))\n",
    "prabowo_before['comments'] = pd.DataFrame(text_normalization(prabowo_before))\n",
    "prabowo_after['comments'] = pd.DataFrame(text_normalization(prabowo_after))\n",
    "secondary_dataset['comments'] = pd.DataFrame(text_normalization(secondary_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index comments\n",
       "0      0        0\n",
       "1      0        0\n",
       "2      1        1\n",
       "3      2        2\n",
       "4      3        3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(anies_after.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal\n",
    "\n",
    "* Stopwords: Stopwords are common words found in many languages such as prepositions, pronouns, etc that do not add much information\n",
    "\n",
    "Stopword examples in English: I, What, An, The, So\n",
    "\n",
    "Stopword examples in Indonesian: Saya, Dan, Akan, Pada, Jadi\n",
    "\n",
    "* Stopwords removal is the process of removing stopwords from the text in a dataset. This is done to help reduce the amount of words in the dataset which will make training the model faster. As stopwords do not contain any important information, their removal does not negatively impact the model that is being trained.\n",
    "\n",
    "https://towardsdatascience.com/text-pre-processing-stop-words-removal-using-different-libraries-f20bac19929a\n",
    "https://yunusmuhammad007.medium.com/basic-text-preprocessing-menggunakan-nltk-86ba3e65a1dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# download nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    datatemps = []\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    for i in range(0, len(data)):\n",
    "        comment = data['comments']  # Access the 'comments' column in the DataFrame\n",
    "        # print(comment)\n",
    "        word_tokens = word_tokenize(comment[i])\n",
    "        #filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        filtered_sentence = []\n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        comment = ' '.join(filtered_sentence)\n",
    "        datatemps.append(comment)\n",
    "    return datatemps\n",
    "\n",
    "# Call the functions successively\n",
    "anies_before['comments'] = pd.DataFrame(remove_stopwords(anies_before))\n",
    "anies_after['comments'] = pd.DataFrame(remove_stopwords(anies_after))\n",
    "ganjar_before['comments'] = pd.DataFrame(remove_stopwords(ganjar_before))\n",
    "ganjar_after['comments'] = pd.DataFrame(remove_stopwords(ganjar_after))\n",
    "prabowo_before['comments'] = pd.DataFrame(remove_stopwords(prabowo_before))\n",
    "prabowo_after['comments'] = pd.DataFrame(remove_stopwords(prabowo_after))\n",
    "secondary_dataset['comments'] = pd.DataFrame(remove_stopwords(secondary_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index comments\n",
       "0      0        0\n",
       "1      0        0\n",
       "2      1        1\n",
       "3      2        2\n",
       "4      3        3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(anies_after.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming / Lemmatization\n",
    "\n",
    "* this one need research (mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index comments\n",
       "0      0        0\n",
       "1      0        0\n",
       "2      1        1\n",
       "3      2        2\n",
       "4      3        3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Sastrawi package\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stemming(data):\n",
    "    datatemps = []\n",
    "    for i in range(0, len(data)):\n",
    "        comment = data['comments']  # Access the 'comments' column in the DataFrame\n",
    "        # print(comment)\n",
    "        comment = stemmer.stem(comment[i])\n",
    "        datatemps.append(comment)\n",
    "    return datatemps\n",
    "\n",
    "# Call the functions successively\n",
    "anies_before['comments'] = pd.DataFrame(stemming(anies_before))\n",
    "anies_after['comments'] = pd.DataFrame(stemming(anies_after))\n",
    "ganjar_before['comments'] = pd.DataFrame(stemming(ganjar_before))\n",
    "ganjar_after['comments'] = pd.DataFrame(stemming(ganjar_after))\n",
    "prabowo_before['comments'] = pd.DataFrame(stemming(prabowo_before))\n",
    "prabowo_after['comments'] = pd.DataFrame(stemming(prabowo_after))\n",
    "secondary_dataset['comments'] = pd.DataFrame(stemming(secondary_dataset))\n",
    "display(anies_after.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index comments\n",
       "0      0        0\n",
       "1      1        1\n",
       "2      2        2\n",
       "3      3        3\n",
       "4      4        4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(secondary_dataset.head())\n",
    "display(prabowo_after.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "* this one need research (mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenization(data):\n",
    "#     datatemps = []\n",
    "#     for i in range(0, len(data)):\n",
    "#         comment = data['comments']  # Access the 'comments' column in the DataFrame\n",
    "#         # print(comment)\n",
    "#         comment = word_tokenize(comment[i])\n",
    "#         datatemps.append(comment)\n",
    "#     return datatemps\n",
    "def tokenization(data):\n",
    "    datatemps = []\n",
    "    for i in range(0, len(data)):\n",
    "        comment = data['comments'][i]  # Access the 'comments' column in the DataFrame\n",
    "        comment = word_tokenize(comment)\n",
    "        datatemps.append(comment)\n",
    "    return datatemps\n",
    "\n",
    "# Call the functions successively\n",
    "# anies_before['comments'] = pd.DataFrame(tokenization(anies_before))\n",
    "# anies_after['comments'] = pd.DataFrame(tokenization(anies_after))\n",
    "# ganjar_before['comments'] = pd.DataFrame(tokenization(ganjar_before))\n",
    "# ganjar_after['comments'] = pd.DataFrame(tokenization(ganjar_after))\n",
    "# prabowo_before['comments'] = pd.DataFrame(tokenization(prabowo_before))\n",
    "# prabowo_after['comments'] = pd.DataFrame(tokenization(prabowo_after))\n",
    "# secondary_dataset['comments'] = pd.DataFrame(tokenization(secondary_dataset))   \n",
    "\n",
    "anies_before['comments'] = tokenization(anies_before)\n",
    "anies_after['comments'] = tokenization(anies_after)\n",
    "ganjar_before['comments'] = tokenization(ganjar_before)\n",
    "ganjar_after['comments'] = tokenization(ganjar_after)\n",
    "prabowo_before['comments'] = tokenization(prabowo_before)\n",
    "prabowo_after['comments'] = tokenization(prabowo_after)\n",
    "secondary_dataset['comments'] = tokenization(secondary_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>username tolol hubungan nya keguguran pakai hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>geblek lo tatacowo banget dibelain balikanhade...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kemarin termewek lengket duh labil banget sih ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intinya kesel att nya anaknya kasihan perkemba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadewwwww permpuan lgsakit jiwaknp peran utama...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  label\n",
       "0  username tolol hubungan nya keguguran pakai hi...      0\n",
       "1  geblek lo tatacowo banget dibelain balikanhade...      0\n",
       "2  kemarin termewek lengket duh labil banget sih ...      0\n",
       "3  intinya kesel att nya anaknya kasihan perkemba...      0\n",
       "4  hadewwwww permpuan lgsakit jiwaknp peran utama...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(secondary_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Minority Oversampling Technique (SMOTE)\n",
    "\n",
    "* this one need research (ivan)\n",
    "* Smote adalah sebuah tehnik yang digunakan terhadap data yang tidak seimbang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE()\n",
    "# X_train_smote, y_train_smote = smote.fit_resample(X_train_tweets_tfidf, y_train.values)\n",
    "# print(X_train_smote.shape, y_train_smote.shape)\n",
    "\n",
    "# # SMOTE on full training data\n",
    "# smote = SMOTE()\n",
    "# X_smote, y_smote = smote.fit_resample(X_tweets_tfidf, y.values)\n",
    "# print(X_smote.shape, y_smote.shape)\n",
    "\n",
    "# # Class Imbalance Check\n",
    "# plt.pie(pd.value_counts(y_train_smote), \n",
    "#         labels=['Label 0 (Positive)', 'Label 1 (Negative)'], \n",
    "#         autopct='%0.1f%%')\n",
    "# plt.axis('equal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "\n",
    "* this one need research (abhi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1656    [anies, pasrah, hasil, pilkada, dki, jakarta, ...\n",
       "752     [kecewa, mata, najwa, malam, mutu, narasi, naj...\n",
       "892     [surabaya, ahy, kalah, garagara, antasari, ya,...\n",
       "1041               [tulus, senang, insyaallah, jalan, bu]\n",
       "1179    [ahok, nista, agama, nista, orang, aku, agama,...\n",
       "Name: comments, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1656    1\n",
       "752     0\n",
       "892     0\n",
       "1041    1\n",
       "1179    0\n",
       "Name: label, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1451    [janji, aniessandi, lho, janji, mas, mohon, ka...\n",
       "1334    [allah, orang, subhanallah, dkijakarta, ahokdj...\n",
       "1761    [bilang, film, jelek, daur, ulang, gagal, imdb...\n",
       "1735    [kalo, nol, bikin, film, perempuan, seksi, bum...\n",
       "1576    [orang, tiga, pilkadadki, cikini, menteng, htt...\n",
       "Name: comments, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1451    0\n",
       "1334    1\n",
       "1761    0\n",
       "1735    0\n",
       "1576    1\n",
       "Name: label, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for now we will use train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation set\n",
    "# for secondary dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(secondary_dataset['comments'], secondary_dataset['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "display(X_train.head())\n",
    "display(y_train.head())\n",
    "\n",
    "display(X_test.head())\n",
    "display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workload Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "<!-- * kemungkinan Binomial Naive Bayes -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Gaussian Naive Bayes\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "# X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# # Train the model\n",
    "# gnb = GaussianNB()\n",
    "# # display(secondary_dataset)\n",
    "# gnb.fit(X_train_vectorized,y_train)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Assuming X_train is a list of lists containing tokenized comments\n",
    "# Convert each list of tokens into a string by joining the tokens\n",
    "X_train_str = [' '.join(tokens) for tokens in X_train]\n",
    "\n",
    "# Use CountVectorizer to vectorize the comments\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train_str)\n",
    "\n",
    "# Assuming X_test is a list of lists containing tokenized comments\n",
    "# Convert each list of tokens into a string by joining the tokens\n",
    "X_test_str = [' '.join(tokens) for tokens in X_test]\n",
    "\n",
    "# Vectorize the test set\n",
    "X_test_vectorized = vectorizer.transform(X_test_str)\n",
    "\n",
    "# Train the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_vectorized.toarray(), y_train)\n",
    "\n",
    "# Make predictions\n",
    "# predictions = gnb.predict(X_test_vectorized.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7113636363636363\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = gnb.predict(X_test_vectorized.toarray())\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train the model\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7681818181818182\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = mnb.predict(X_test_vectorized.toarray())\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 1007,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Train the model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7659090909090909\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bnb.predict(X_test_vectorized.toarray())\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "* this one need research (pat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis the data from primary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index comments\n",
       "0      0      [0]\n",
       "1      1      [1]\n",
       "2      2      [2]\n",
       "3      3      [3]\n",
       "4      4      [4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_sentiment(model, vectorizer, text):\n",
    "    # Vectorize the input text\n",
    "    text_vectorized = vectorizer.transform([text])\n",
    "    \n",
    "    # Make predictions\n",
    "    prediction = model.predict(text_vectorized.toarray())\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "# Test the model\n",
    "# print(predict_sentiment(gnb, vectorizer, text))\n",
    "# anies before\n",
    "anies_before_count_positif = 0\n",
    "anies_before_count_negatif = 0\n",
    "display(anies_before.head())\n",
    "# for i in range(0, len(anies_before)):\n",
    "#     prediction = predict_sentiment(gnb, vectorizer, anies_before['comments'][i])\n",
    "#     if prediction == 1:\n",
    "#         anies_before_count_positif += 1\n",
    "#     else:\n",
    "#         anies_before_count_negatif += 1\n",
    "# print('anies before positif: ', anies_before_count_positif)\n",
    "# print('anies before negatif: ', anies_before_count_negatif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modal Comprarison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
